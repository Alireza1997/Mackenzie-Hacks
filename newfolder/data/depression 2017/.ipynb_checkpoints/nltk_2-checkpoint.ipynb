{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string \n",
    "import nltk # Imports the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> d\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> stopwords\n",
      "    Downloading package stopwords to /Users/shreyparikh/nltk_data...\n",
      "      Unzipping corpora/stopwords.zip.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n"
     ]
    }
   ],
   "source": [
    "nltk.download_shell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Toronto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>id</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cpl Ryan W. Voll ret</td>\n",
       "      <td>842547573420425216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#MentalHealth #Anxiety #Depression #MyLife #Tr...</td>\n",
       "      <td>2017-03-17T01:26:09</td>\n",
       "      <td>CplRyanWVollRet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sayu Healthy Living</td>\n",
       "      <td>844377415820464128</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>What's eating you?   #stress #depression #anxi...</td>\n",
       "      <td>2017-03-22T02:37:18</td>\n",
       "      <td>SAYU2Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Justin Roopnarine</td>\n",
       "      <td>846179479731027972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>#Depression can happen to anybody. #LetsTalk: ...</td>\n",
       "      <td>2017-03-27T01:58:03</td>\n",
       "      <td>jroopnarine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deborah Peniuk</td>\n",
       "      <td>850389644592238592</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Today is #WorldHealthDay! #Repost from who #DY...</td>\n",
       "      <td>2017-04-07T16:47:45</td>\n",
       "      <td>TraveliciousDee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jules</td>\n",
       "      <td>855237562566193152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#camh #anxiety #depression #change @ CAMH - Ce...</td>\n",
       "      <td>2017-04-21T01:51:39</td>\n",
       "      <td>obsessivejules</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               fullname                  id  likes  replies  retweets  \\\n",
       "0  Cpl Ryan W. Voll ret  842547573420425216      0        0         0   \n",
       "1   Sayu Healthy Living  844377415820464128      2        1         0   \n",
       "2     Justin Roopnarine  846179479731027972      0        0         1   \n",
       "3        Deborah Peniuk  850389644592238592      1        0         0   \n",
       "4                 Jules  855237562566193152      0        0         0   \n",
       "\n",
       "                                                text            timestamp  \\\n",
       "0  #MentalHealth #Anxiety #Depression #MyLife #Tr...  2017-03-17T01:26:09   \n",
       "1  What's eating you?   #stress #depression #anxi...  2017-03-22T02:37:18   \n",
       "2  #Depression can happen to anybody. #LetsTalk: ...  2017-03-27T01:58:03   \n",
       "3  Today is #WorldHealthDay! #Repost from who #DY...  2017-04-07T16:47:45   \n",
       "4  #camh #anxiety #depression #change @ CAMH - Ce...  2017-04-21T01:51:39   \n",
       "\n",
       "              user  \n",
       "0  CplRyanWVollRet  \n",
       "1      SAYU2Health  \n",
       "2      jroopnarine  \n",
       "3  TraveliciousDee  \n",
       "4   obsessivejules  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(columns='Words'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Words]\n",
       "Index: []"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check to make sure its working\n",
    "df2['Words'] = df['text'].apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[MentalHealth, Anxiety, Depression, MyLife, Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Whats, eating, stress, depression, anxiety, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Depression, happen, anybody, LetsTalk, never,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Today, WorldHealthDay, Repost, DYK, Depressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[camh, anxiety, depression, change, CAMH, Cent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[mentalhealth, friday, health, healing, educat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[nofiltertshirtco, djglifestyle, djgimports, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[alternative, depression, therapy, meme, memes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Weather, depression, City, toronto, weather, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[depressed, depression, overworked, problems, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Im, Going, Krazy, FucKDaWorld, Depression, Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[Hope, youre, good, day, gaychub, gay, lgbt, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[culinarychronic, depression, hertZ, youre, sc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Words\n",
       "0   [MentalHealth, Anxiety, Depression, MyLife, Tr...\n",
       "1   [Whats, eating, stress, depression, anxiety, t...\n",
       "2   [Depression, happen, anybody, LetsTalk, never,...\n",
       "3   [Today, WorldHealthDay, Repost, DYK, Depressio...\n",
       "4   [camh, anxiety, depression, change, CAMH, Cent...\n",
       "5   [mentalhealth, friday, health, healing, educat...\n",
       "6   [nofiltertshirtco, djglifestyle, djgimports, s...\n",
       "7   [alternative, depression, therapy, meme, memes...\n",
       "8   [Weather, depression, City, toronto, weather, ...\n",
       "9   [depressed, depression, overworked, problems, ...\n",
       "10  [Im, Going, Krazy, FucKDaWorld, Depression, Sc...\n",
       "11  [Hope, youre, good, day, gaychub, gay, lgbt, t...\n",
       "12  [culinarychronic, depression, hertZ, youre, sc..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MentalHealth': 19, 'Anxiety': 1, 'Depression': 7, 'MyLife': 20, 'TrueStory': 29, 'Seneca': 27, 'Newnham': 21, 'Res': 25, 'httpswwwinstagramcompBRuII63AV': 68, 'Whats': 32, 'eating': 51, 'stress': 103, 'depression': 47, 'anxiety': 37, 'toronto': 106, 'etobicoke': 54, 'psychology': 96, 'psychotherapy…': 97, 'httpswwwinstagramcompBR7IQOvASFS': 67, 'happen': 62, 'anybody': 38, 'LetsTalk': 17, 'never': 89, 'afraid': 35, 'ask': 39, 'help': 65, 'WHO…': 30, 'httpswwwinstagramcompBSH7vOqgYhF': 69, 'Today': 28, 'WorldHealthDay': 33, 'Repost': 24, 'DYK': 6, 'leading': 80, 'cause': 42, 'disability…': 48, 'httpwwwinstagramcomlnishmrPv': 79, 'camh': 41, 'change': 43, 'CAMH': 3, 'Centre': 4, 'Addiction': 0, 'Mental': 18, 'Health': 12, 'httpswwwinstagramcompBTIS4GKhNLT': 70, 'mentalhealth': 86, 'friday': 55, 'health': 64, 'healing': 63, 'education': 52, 'stopthestigma': 102, 'PTSD…': 23, 'httpswwwinstagramcompBTucVFlaKA': 71, 'nofiltertshirtco': 90, 'djglifestyle': 50, 'djgimports': 49, 'sportit': 101, 'entrepreneurlife': 53, 'sleep': 100, 'love…': 82, 'httpswwwinstagramcompBUP3pUlSzu': 72, 'alternative': 36, 'therapy': 105, 'meme': 84, 'memes': 85, 'notfunny': 91, 'funny': 57, 'seriouslyfunny': 99, 'supremeleader…': 104, 'httpswwwinstagramcompBVq23h9H39B': 73, 'Weather': 31, 'City': 5, 'weather': 107, 'photography': 93, 'blackandwhite…': 40, 'httpswwwinstagramcompBWgyQG2hwRi': 74, 'depressed': 46, 'overworked': 92, 'problems': 95, 'money': 87, 'medicine': 83, 'pills': 94, 'Fucital': 10, 'fun': 56, 'funny…': 58, 'httpswwwinstagramcompBXRsPWnh44W': 75, 'Im': 14, 'Going': 11, 'Krazy': 16, 'FucKDaWorld': 9, 'Scarborough': 26, 'Junction': 15, 'httpswwwinstagramcompBXf1g8Jg0eXDzz7pFbOxx6N1ocdQL0OXwemY8c0': 76, '…': 109, 'Hope': 13, 'youre': 108, 'good': 61, 'day': 45, 'gaychub': 60, 'gay': 59, 'lgbt': 81, 'n7': 88, 'North': 22, 'York': 34, 'httpswwwinstagramcompBXggsWZAr5k': 77, 'culinarychronic': 44, 'hertZ': 66, 'scum': 98, 'BonAppetit': 2, 'Etobicoke': 8, 'httpswwwinstagramcompBZz4OvDlUfO': 78}\n"
     ]
    }
   ],
   "source": [
    "# Might take awhile...\n",
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(df['text'])\n",
    "\n",
    "# Print total number of vocab words\n",
    "print(bow_transformer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 19)\t1\n",
      "  (0, 20)\t1\n",
      "  (0, 21)\t1\n",
      "  (0, 25)\t1\n",
      "  (0, 27)\t1\n",
      "  (0, 29)\t1\n",
      "  (0, 68)\t1\n",
      "  (1, 32)\t1\n",
      "  (1, 37)\t1\n",
      "  (1, 47)\t1\n",
      "  (1, 51)\t1\n",
      "  (1, 54)\t1\n",
      "  (1, 67)\t1\n",
      "  (1, 96)\t1\n",
      "  (1, 97)\t1\n",
      "  (1, 103)\t1\n",
      "  (1, 106)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 17)\t1\n",
      "  (2, 30)\t1\n",
      "  (2, 35)\t1\n",
      "  (2, 38)\t1\n",
      "  (2, 39)\t1\n",
      "  :\t:\n",
      "  (10, 16)\t1\n",
      "  (10, 26)\t1\n",
      "  (10, 76)\t1\n",
      "  (10, 109)\t1\n",
      "  (11, 13)\t1\n",
      "  (11, 22)\t1\n",
      "  (11, 34)\t1\n",
      "  (11, 45)\t1\n",
      "  (11, 47)\t1\n",
      "  (11, 59)\t1\n",
      "  (11, 60)\t1\n",
      "  (11, 61)\t1\n",
      "  (11, 77)\t1\n",
      "  (11, 81)\t1\n",
      "  (11, 88)\t1\n",
      "  (11, 106)\t1\n",
      "  (11, 108)\t1\n",
      "  (12, 2)\t1\n",
      "  (12, 8)\t1\n",
      "  (12, 44)\t1\n",
      "  (12, 47)\t1\n",
      "  (12, 66)\t1\n",
      "  (12, 78)\t1\n",
      "  (12, 98)\t1\n",
      "  (12, 108)\t1\n"
     ]
    }
   ],
   "source": [
    "messages_bow = bow_transformer.transform(df['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messages_tfidf = tfidf_transformer.transform(messages_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 68)\t0.343509415688\n",
      "  (0, 29)\t0.343509415688\n",
      "  (0, 27)\t0.343509415688\n",
      "  (0, 25)\t0.343509415688\n",
      "  (0, 21)\t0.343509415688\n",
      "  (0, 20)\t0.343509415688\n",
      "  (0, 19)\t0.343509415688\n",
      "  (0, 7)\t0.236664848821\n",
      "  (0, 1)\t0.343509415688\n",
      "  (1, 106)\t0.264237139417\n",
      "  (1, 103)\t0.345539624742\n",
      "  (1, 97)\t0.345539624742\n",
      "  (1, 96)\t0.345539624742\n",
      "  (1, 67)\t0.345539624742\n",
      "  (1, 54)\t0.345539624742\n",
      "  (1, 51)\t0.345539624742\n",
      "  (1, 47)\t0.156761099882\n",
      "  (1, 37)\t0.264237139417\n",
      "  (1, 32)\t0.345539624742\n",
      "  (2, 89)\t0.324876271899\n",
      "  (2, 69)\t0.324876271899\n",
      "  (2, 65)\t0.324876271899\n",
      "  (2, 62)\t0.324876271899\n",
      "  (2, 39)\t0.324876271899\n",
      "  (2, 38)\t0.324876271899\n",
      "  :\t:\n",
      "  (10, 14)\t0.343509415688\n",
      "  (10, 11)\t0.343509415688\n",
      "  (10, 9)\t0.343509415688\n",
      "  (10, 7)\t0.236664848821\n",
      "  (11, 108)\t0.253919065923\n",
      "  (11, 106)\t0.225165063399\n",
      "  (11, 88)\t0.294445556304\n",
      "  (11, 81)\t0.294445556304\n",
      "  (11, 77)\t0.294445556304\n",
      "  (11, 61)\t0.294445556304\n",
      "  (11, 60)\t0.294445556304\n",
      "  (11, 59)\t0.294445556304\n",
      "  (11, 47)\t0.1335812334\n",
      "  (11, 45)\t0.294445556304\n",
      "  (11, 34)\t0.294445556304\n",
      "  (11, 22)\t0.294445556304\n",
      "  (11, 13)\t0.294445556304\n",
      "  (12, 108)\t0.327125139097\n",
      "  (12, 98)\t0.379335609212\n",
      "  (12, 78)\t0.379335609212\n",
      "  (12, 66)\t0.379335609212\n",
      "  (12, 47)\t0.172093337686\n",
      "  (12, 44)\t0.379335609212\n",
      "  (12, 8)\t0.379335609212\n",
      "  (12, 2)\t0.379335609212\n"
     ]
    }
   ],
   "source": [
    "print(messages_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-114-e38b6ff13152>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-114-e38b6ff13152>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df3 = pd.DataFrame(index = 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, columns='Weight'.split())\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.DataFrame(index = , columns='Weight'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Words</th>\n",
       "      <td>Addiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Weight\n",
       "Words  Addiction"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = \"\"\n",
    "for i in range(len(bow_transformer.vocabulary_)):\n",
    "    s += bow_transformer.get_feature_names()[i] \n",
    "    s += \" \"\n",
    "    #df3[\"Weight\"] = tfidf_transformer.idf_[bow_transformer.vocabulary_[bow_transformer.get_feature_names()[i]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addiction Anxiety BonAppetit CAMH Centre City DYK Depression Etobicoke FucKDaWorld Fucital Going Health Hope Im Junction Krazy LetsTalk Mental MentalHealth MyLife Newnham North PTSD… Repost Res Scarborough Seneca Today TrueStory WHO… Weather Whats WorldHealthDay York afraid alternative anxiety anybody ask blackandwhite… camh cause change culinarychronic day depressed depression disability… djgimports djglifestyle eating education entrepreneurlife etobicoke friday fun funny funny… gay gaychub good happen healing health help hertZ httpswwwinstagramcompBR7IQOvASFS httpswwwinstagramcompBRuII63AV httpswwwinstagramcompBSH7vOqgYhF httpswwwinstagramcompBTIS4GKhNLT httpswwwinstagramcompBTucVFlaKA httpswwwinstagramcompBUP3pUlSzu httpswwwinstagramcompBVq23h9H39B httpswwwinstagramcompBWgyQG2hwRi httpswwwinstagramcompBXRsPWnh44W httpswwwinstagramcompBXf1g8Jg0eXDzz7pFbOxx6N1ocdQL0OXwemY8c0 httpswwwinstagramcompBXggsWZAr5k httpswwwinstagramcompBZz4OvDlUfO httpwwwinstagramcomlnishmrPv leading lgbt love… medicine meme memes mentalhealth money n7 never nofiltertshirtco notfunny overworked photography pills problems psychology psychotherapy… scum seriouslyfunny sleep sportit stopthestigma stress supremeleader… therapy toronto weather youre … \n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df4 = pd.DataFrame(index = s.split(), columns='Weight'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame(index = s.split(), columns='Weight'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Weight\n",
      "Addiction           NaN\n",
      "Anxiety             NaN\n",
      "BonAppetit          NaN\n",
      "CAMH                NaN\n",
      "Centre              NaN\n",
      "City                NaN\n",
      "DYK                 NaN\n",
      "Depression          NaN\n",
      "Etobicoke           NaN\n",
      "FucKDaWorld         NaN\n",
      "Fucital             NaN\n",
      "Going               NaN\n",
      "Health              NaN\n",
      "Hope                NaN\n",
      "Im                  NaN\n",
      "Junction            NaN\n",
      "Krazy               NaN\n",
      "LetsTalk            NaN\n",
      "Mental              NaN\n",
      "MentalHealth        NaN\n",
      "MyLife              NaN\n",
      "Newnham             NaN\n",
      "North               NaN\n",
      "PTSD…               NaN\n",
      "Repost              NaN\n",
      "Res                 NaN\n",
      "Scarborough         NaN\n",
      "Seneca              NaN\n",
      "Today               NaN\n",
      "TrueStory           NaN\n",
      "...                 ...\n",
      "leading             NaN\n",
      "lgbt                NaN\n",
      "love…               NaN\n",
      "medicine            NaN\n",
      "meme                NaN\n",
      "memes               NaN\n",
      "mentalhealth        NaN\n",
      "money               NaN\n",
      "n7                  NaN\n",
      "never               NaN\n",
      "nofiltertshirtco    NaN\n",
      "notfunny            NaN\n",
      "overworked          NaN\n",
      "photography         NaN\n",
      "pills               NaN\n",
      "problems            NaN\n",
      "psychology          NaN\n",
      "psychotherapy…      NaN\n",
      "scum                NaN\n",
      "seriouslyfunny      NaN\n",
      "sleep               NaN\n",
      "sportit             NaN\n",
      "stopthestigma       NaN\n",
      "stress              NaN\n",
      "supremeleader…      NaN\n",
      "therapy             NaN\n",
      "toronto             NaN\n",
      "weather             NaN\n",
      "youre               NaN\n",
      "…                   NaN\n",
      "\n",
      "[110 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(bow_transformer.vocabulary_)):\n",
    "    weight_x=(tfidf_transformer.idf_[bow_transformer.vocabulary_[bow_transformer.get_feature_names()[i]]])\n",
    "    df4.at[bow_transformer.get_feature_names()[i], \"Weight\"] = weight_x;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Weight\n",
      "Addiction         2.94591\n",
      "Anxiety           2.94591\n",
      "BonAppetit        2.94591\n",
      "CAMH              2.94591\n",
      "Centre            2.94591\n",
      "City              2.94591\n",
      "DYK               2.94591\n",
      "Depression        2.02962\n",
      "Etobicoke         2.94591\n",
      "FucKDaWorld       2.94591\n",
      "Fucital           2.94591\n",
      "Going             2.94591\n",
      "Health            2.94591\n",
      "Hope              2.94591\n",
      "Im                2.94591\n",
      "Junction          2.94591\n",
      "Krazy             2.94591\n",
      "LetsTalk          2.94591\n",
      "Mental            2.94591\n",
      "MentalHealth      2.94591\n",
      "MyLife            2.94591\n",
      "Newnham           2.94591\n",
      "North             2.94591\n",
      "PTSD…             2.94591\n",
      "Repost            2.94591\n",
      "Res               2.94591\n",
      "Scarborough       2.94591\n",
      "Seneca            2.94591\n",
      "Today             2.94591\n",
      "TrueStory         2.94591\n",
      "...                   ...\n",
      "leading           2.94591\n",
      "lgbt              2.94591\n",
      "love…             2.94591\n",
      "medicine          2.94591\n",
      "meme              2.94591\n",
      "memes             2.94591\n",
      "mentalhealth      2.94591\n",
      "money             2.94591\n",
      "n7                2.94591\n",
      "never             2.94591\n",
      "nofiltertshirtco  2.94591\n",
      "notfunny          2.94591\n",
      "overworked        2.94591\n",
      "photography       2.94591\n",
      "pills             2.94591\n",
      "problems          2.94591\n",
      "psychology        2.94591\n",
      "psychotherapy…    2.94591\n",
      "scum              2.94591\n",
      "seriouslyfunny    2.94591\n",
      "sleep             2.94591\n",
      "sportit           2.94591\n",
      "stopthestigma     2.94591\n",
      "stress            2.94591\n",
      "supremeleader…    2.94591\n",
      "therapy           2.94591\n",
      "toronto           2.25276\n",
      "weather           2.94591\n",
      "youre             2.54045\n",
      "…                 2.94591\n",
      "\n",
      "[110 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
